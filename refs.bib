@string{pacmpl = "Proceedings of the ACM on Programming Languages"}

@InProceedings{flores-montoya:fm16,
    author="Flores-Montoya, Antonio",
    editor="Fitzgerald, John
        and Heitmeyer, Constance
        and Gnesi, Stefania
        and Philippou, Anna",
    title="Upper and Lower Amortized Cost Bounds of Programs Expressed as Cost Relations",
    booktitle="FM 2016: Formal Methods",
    year="2016",
    publisher="Springer International Publishing",
    series="Lecture Notes in Computer Science",
    volume={9995},
    pages="254--273",
    doi={10.1007/978-3-319-48989-6\_16}
}


@article{albert-et-al:jar11,
	author = "Elvira Albert and Puri Arenas and Samir Genaim and Germán Puebla",
	doi = "10.1007/s10817-010-9174-1",
	issue = "2",
	journal = "Journal of Automated Reasoning",
	keywords = "programming languages; higher-order complexity",
	pages = "161–203",
	title = "{Closed-form upper bounds in static cost analysis}",
	volume = "46",
	year = "2011"
}

@article{albert-et-al:tcs12:cost-analysis,
	author = "Elvira Albert and Puri Arenas and Samir Genaim and German Puebla and Damiano Zanardini",
	doi = "10.1016/j.tcs.2011.07.009",
	journal = "Theoretical Computer Science",
	keywords = "higher-order complexity",
	number = "1",
	pages = "142–159",
	title = "{Cost analysis of object-oriented bytecode programs}",
	volume = "413",
	year = "2012"
}

@article{albert-et-al:tocl13:inference,
	author = "Elvira Albert and Samir Genaim and Abu Naser Masud",
	doi = "10.1145/2499937.2499943",
	journal = "ACM Transactions on Computational Logic",
	keywords = "higher-order complexity",
	number = "3",
	pages = "22:1–22:35",
	title = "{On the Inference of Resource Usage Upper and Lower Bounds}",
	volume = "14",
	year = "2013"
}

@InProceedings{alonso-blas-genaim:sas12,
    doi = {10.1007/978-3-642-33125-1\_27},
author="Alonso-Blas, Diego Esteban and Genaim, Samir",
editor="Min{\'e}, Antoine and Schmidt, David",
title="On the limits of the classical approach to cost analysis",
booktitle="Static Analysis",
year="2012",
publisher="Springer Berlin Heidelberg",
pages="405--421",
series={Lecture Notes in Computer Science},
volume={7460}
}

@inproceedings{danner-et-al:icfp15,
	author = {Danner, Norman and Licata, Daniel R. and Ramyaa, Ramyaa},
	crossref = {proc:icfp15},
	date-added = {2015-05-12 09:30:09 -0400},
	date-modified = {2015-06-05 14:24:22 -0400},
	doi = {10.1145/2784731.2784749},
	pages = {140--151},
	title = {{Denotational cost semantics for functional languages with inductive types}},
	year = {2015}
}



@InProceedings{lsr,
  author =	{Daniel R. Licata and Michael Shulman and Mitchell Riley},
  title =	{{A fibrational framework for substructural and modal logics}},
  booktitle =	{2nd International Conference on Formal Structures for
               Computation and Deduction, FSCD 2017},
  pages =	{25:1--25:22},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  year =	{2017},
  volume =	{84},
  editor =	{Dale Miller},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  doi =		{10.4230/LIPIcs.FSCD.2017.25},
}

@book{clrs,
 author = {{Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford}},
 title = {Introduction to Algorithms, Third Edition},
 year = {2009},
 isbn = {0262033844, 9780262033848},
 edition = {3rd},
 publisher = {The MIT Press},
} 

@mastersthesis{hudson, 
title={{Computer-Checked Recurrence Extraction for Functional Programs}},
author={{Hudson, Bowornmet}},
year={{2016}},
school={{Wesleyan University}}
}

@inproceedings{danner-et-al:plpv13,
	author = {Danner, Norman and Paykin, Jennifer and Royer, James S.},
	booktitle = {{Proceedings of the 7th workshop on {P}rogramming languages
              meets program verification, PLPV 2013}},
	date-added = {2012-11-26 09:56:35 -0500},
	date-modified = {2013-04-02 14:36:50 -0400},
	doi = {10.1145/2428116.2428123},
	editor = {Might, Matthew and Horn, David Van},
	keywords = {implicit computational complexity},
	pages = {25--34},
	publisher = {ACM Press},
	title = {{A static cost analysis for a higher-order language}},
	year = {2013}
}

@inproceedings{mcbride:plenty-o-nuttin,
    author = {Conor McBride},
    booktitle = {A List of Successes That Can Change the World: Essays
                 Dedicated to Philip Wadler on the Occasion of His 60th
                 Birthday},
    title = {I got plenty o' Nuttin'},
    editor = {Sam Lindley and Conor McBride and Phil Trinder and Don Sannella},
    series = {Lecture Notes in Computer Science},
    volume = {9600},
    publisher = {Springer-Verlag},
    year = {2016},
    doi = {10.1007/978-3-319-30936-1\_12}
}

@inproceedings{atkey:lics18,
 author = {Atkey, Robert},
 title = {Syntax and semantics of quantitative type theory},
 booktitle = {Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in
              Computer Science, LICS 2018},
 year = {2018},
 location = {Oxford, United Kingdom},
 pages = {56--65},
 doi = {10.1145/3209108.3209189},
 publisher = {ACM Press},
}

@article{kavvos-et-al:popl20,
author = {Kavvos, G. A. and Morehouse, Edward and Licata, Daniel R. and Danner, Norman},
title = {Recurrence Extraction for Functional Programs through Call-by-Push-Value},
year = {2019},
issue_date = {January 2020},
volume = {4},
number = {POPL},
doi = {10.1145/3371083},
journal = pacmpl,
articleno = {Article 15},
}



@misc{danner-licata:jfp-in-prep,
	author = {Danner, Norman and Licata, Daniel R.},
	title = {Denotational semantics as a foundation for cost recurrence extraction for functional languages},
    archiveprefix={arXiv},
    eprint={2002.07262v1},
    year={2020}
}

@misc{cutler-et-al:icfp2020-full,
	author = {Cutler, Joseph W. and Licata, Daniel R. and Danner, Norman},
	title = {Denotational recurrence extraction for amortized analysis},
    archiveprefix={arXiv},
    eprint={2006.15036},
	year = {2020}
}


@inproceedings{hoffmann-et-al:popl17,
	author = {Hoffmann, Jan and Das, Ankush and Weng, Shu{-}Chun},
	booktitle = {Proceedings of the 44th {ACM} {SIGPLAN} Symposium on
              Principles of Programming Languages, {POPL} 2017},
	crossref = {proc:popl17},
	pages = {359--373},
	title = {Towards automatic resource bound analysis for {OCaml}},
    doi = {10.1145/3009837.3009842},
	year = {2017}
}

@inproceedings{mitchell-plotkin:popl85,
	author = {Mitchell, John C. and Plotkin, Gordon D.},
	title = {Abstract types have existential types},
	year = {1985},
	doi = {10.1145/318593.318606},
	booktitle = {Proceedings of the 12th {ACM} {SIGACT-SIGPLAN} Symposium on Principles of Programming Languages, {POPL} 1985},
	pages = {37–51},
	numpages = {15},
}



@article{wegbreit:cacm75,
	author = {Wegbreit, Ben},
	date-added = {2012-11-06 11:36:50 -0500},
	date-modified = {2012-11-06 11:41:17 -0500},
	doi = {10.1145/361002.361016},
	journal = {Communications of the Association for Computing Machinery},
	keywords = {higher-order complexity},
	number = {9},
	pages = {528--539},
	title = {{Mechanical program analysis}},
	volume = {18},
	year = {1975}
}

@inproceedings{rosendahl:auto-complexity-analysis,
	author = {Rosendahl, Mads},
	crossref = {proc:fpca89},
	date-added = {2012-05-23 16:34:27 -0400},
	date-modified = {2012-11-12 10:46:17 -0500},
	doi = {10.1145/99370.99381},
	keywords = {higher-order complexity},
	pages = {144--156},
	title = {{Automatic complexity analysis}}
}

@article{lematayer:toplas88,
	author = {{Le M{\'e}tayer}, Daniel},
	date-added = {2012-11-06 10:50:03 -0500},
	date-modified = {2012-11-06 11:03:45 -0500},
	doi = {10.1145/42190.42347},
	journal = {ACM Transactions on Programming Languages and Systems},
	keywords = {higher-order complexity},
	number = {2},
	pages = {248--266},
	title = {{{ACE}: an automatic complexity evaluator}},
	volume = {10},
	year = {1988}
}
@article{hoffmann-et-al:toplas12:multivariate-amortized,
	author = {Hoffmann, Jan and Aehlig, Klaus and Hofmann, Martin},
	doi = {10.1145/2362389.2362393},
	journal = {ACM Transactions on Programming Languages and Systems},
	number = {3},
	pages = {14:1--14:62},
	title = {{Multivariate Amortized Resource Analysis}},
	volume = {34},
	year = {2012}
}

@inproceedings{hoffmann-shao:esop15:parallel,
	author = {Hoffmann, Jan and Shao, Zhong},
	booktitle = {{Programming Languages and Systems: 24th European Symposium on Programming, ESOP 2015}},
	date-added = {2015-01-19 13:34:19 -0500},
	date-modified = {2015-05-27 12:07:35 -0400},
	doi = {10.1007/978-3-662-46669-8\_6},
	editor = {Vitek, Jan},
	keywords = {higher-order complexity},
	pages = {132--157},
	publisher = {Springer-Verlag},
	series = {{Lecture Notes in Computer Science}},
	title = {{Automatic static cost analysis for parallel programs}},
	volume = {9032},
	year = {2015}
}


@inproceedings{niu-hoffmann:lpar18,
	author = {Niu, Yue and Hoffmann, Jan},
	bibsource = {EasyChair, https://easychair.org},
	booktitle = {LPAR-22. 22nd International Conference on Logic for Programming, Artificial Intelligence and Reasoning},
	doi = {10.29007/xkwx},
	editor = {Barthe, Gilles and Sutcliffe, Geoff and Veanes, Margus},
	issn = {2398-7340},
	pages = {543--563},
	publisher = {EasyChair},
	series = {EPiC Series in Computing},
	title = {Automatic Space Bound Analysis for Functional Programs with Garbage Collection},
	volume = {57},
	year = {2018}
}

@article{jost-et-al:jar17,
	author = {Jost, Steffen and Vasconcelos, Pedro and Florido, M{\'a}rio and Hammond, Kevin},
	doi = {10.1007/s10817-016-9398-9},
	journal = {Journal of Automated Reasoning},
	number = {1},
	pages = {87--120},
	title = {Type-based cost analysis for lazy functional languages},
	volume = {59},
	year = {2017}
}

@book{okasaki:purely-functional-data-structures,
	author = {Okasaki, Chris},
	booktitle = {{Purely Functional Data Structures}},
	date-added = {2015-01-16 16:35:37 -0500},
	date-modified = {2015-01-16 16:36:22 -0500},
	publisher = {Cambridge University Press},
	title = {{Purely Functional Data Structures}},
	year = {1998}
}

@article{benzinger:tcs04,
	author = {Benzinger, Ralph},
	doi = {10.1016/j.tcs.2003.10.022},
	journal = {Theoretical Computer Science},
	keywords = {higher-order complexity},
	number = {1-2},
	pages = {79--103},
	title = {{Automated higher-order complexity analysis}},
	volume = {318},
	year = {2004}
}

@article{danner-royer:ats-lmcs,
	author = {Danner, Norman and Royer, James S.},
	doi = {10.2168/LMCS-3(1:9)2007},
	journal = {Logical Methods in Computer Science},
	keywords = {implicit computational complexity},
	number = {9},
	pages = {1--53},
	title = {{Adventures in time and space}},
	volume = {3},
	year = {2007}
}

@techreport{shultis:complexity,
	author = {Shultis, Jon},
	institution = {University of Colorado at Boulder},
	keywords = {higher-order complexity},
	number = {CU-CS-288-85},
	title = {{On the complexity of higher-order programs}},
	year = {1985}
}

@phdthesis{sands:thesis,
	author = {Sands, David},
	keywords = {higher-order complexity},
	school = {University of London},
	title = {{Calculi for Time Analysis of Functional Programs}},
	year = {1990}
}


@phdthesis{vanstone:thesis,
	author = {Stone, Kathryn Van},
	school = {Carnegie Mellon University},
	title = {{A Denotational Approach to Measuring Complexity in Functional Programs}},
	year = {2003}
}

@article{orchard-et-al:icfp19:graded-modal-types,
	author = {Orchard, Dominic and Liepelt, Vilem-Benjamin and {Eades III}, Harley},
	doi = {10.1145/3341714},
	journal = pacmpl,
	number = {ICFP},
	pages = {110:1--110:30},
	publisher = {ACM Press},
	title = {Quantitative program reasoning with graded modal types},
	volume = {3},
	year = {2019}
}

@article{girard-et-al:tcs92:bll,
	author = {Girard, Jean-Yves and Scedrov, Andre and Scott, Philip J.},
	doi = {10.1016/0304-3975(92)90386-T},
	journal = {Theoretical Computer Science},
	number = {1},
	pages = {1--66},
	title = {Bounded linear logic: a modular approach to polynomial-time computability},
	volume = {97},
	year = {1992}
}



@inproceedings{danielsson:popl08,
	author = "Nils Anders Danielsson",
	crossref = "proc:popl08",
	doi = "10.1145/1328438.1328457",
	keywords = "higher-order complexity",
	pages = "133–144",
	title = "{Lightweight semiformal time complexity analysis for purely functional data structures}"
}

@article{tarjan:amortized-complexity,
	author = "Robert Endre Tarjan",
	doi = "10.1137/0606031",
	journal = "{SIAM} Journal on Algebraic and Discrete Methods",
	number = "2",
	pages = "306–318",
	title = "{Amortized computational complexity}",
	volume = "6",
	year = "1985"
}

@unpublished{reed:names-useless,
    author = {Jason Reed},
    title = {Names are (mostly) useless},
    note = {Presented at 3rd Informal {ACM} {SIGPLAN} Workshop on Mechanizing
            Metatheory 2008},
    url = {https://www.cis.upenn.edu/~sweirich/wmm/wmm08-programme.html}
}

@unpublished{pierce:lics03,
    author = {Benjamin Pierce},
    title = {Types and Programming Languages: The Next Generation},
    note = {Presented at Eighteenth Annual IEEE Symposium on Logic In Computer Science (2003(},
    url = {https://www.cis.upenn.edu/~bcpierce/papers/tng-lics2003-slides.pdf}
}

@article{kincaid-et-al:popl18:ocrs,
 author = {Kincaid, Zachary and Cyphert, John and Breck, Jason and Reps, Thomas},
 title = {Non-linear Reasoning for Invariant Synthesis},
 journal = pacmpl,
 issue_date = {January 2018},
 volume = {2},
 number = {POPL},
 month = dec,
 year = {2017},
 issn = {2475-1421},
 pages = {54:1--54:33},
 articleno = {54},
 numpages = {33},
 url = {http://doi.acm.org/10.1145/3158142},
 doi = {10.1145/3158142},
 acmid = {3158142},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Invariant generation, Operational calculus, Recurrence relation},
} 

@inproceedings{hofmann02diamonds,
author = {Hofmann, Martin},
title = {The Strength of Non-Size Increasing Computation},
year = {2002},
doi = {10.1145/503272.503297},
booktitle = {Proceedings of the 29th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {260–269},
}


@Article{hofmann03diamonds-journal,
  author =       {Martin Hofmann},
  title =        {Linear Types and Non-Size-Increasing Polynomial Time Computation},
  journal =      {Information and Computation},
  year =         {2003},
  volume =    {183},
  number =    {1},
  pages =     {57--85},
  doi = {10.1016/S0890-5401(03)00009-9}
}

@inproceedings{hofmannjost03aara,
	author = "Martin Hofmann and Steffen Jost",
	crossref = "proc:popl03",
	doi = "10.1145/604131.604148",
	keywords = "higher-order complexity",
	pages = "185–197",
	title = "{Static prediction of heap space usage for first-order functional programs}"
}

@InProceedings{knoth+19resourceguided,
  author = {Knoth, Tristan and Wang, Di and Polikarpova, Nadia and Hoffmann, Jan},
  title = {Resource-Guided Program Synthesis},
  booktitle = {ACM SIGPLAN Conference on Programming Language Design and Implementation},
  year =      {2019},
}

@Article{sleator-tarjan-85,
  author =       {Daniel Dominic Sleator and Robert Endre Tarjan},
  title =        {Self-adjusting binary search trees},
  journal =      {Journal of the {ACM}},
  year =         {1985},
  volume =    {32},
  number =    {3}
}

@article{wang-et-al:oopsla17:timl,
	author = {Wang, Peng and Wang, Di and Chlipala, Adam},
	title = {TiML: A functional language for practical complexity analysis with invariants},
	year = {2017},
	volume = {1},
	number = {OOPSLA},
	doi = {10.1145/3133903},
	journal = pacmpl,
	articleno = {79},
	numpages = {26},
}



@proceedings{proc:fpca89,
	booktitle = {{Proceedings of the Fourth International Conference on
              Functional Programming Languages and Computer Architecture, FPCA
              1989}},
	date-added = {2012-11-12 10:44:40 -0500},
	date-modified = {2012-11-12 10:46:38 -0500},
	editor = {Stoy, Joseph E.},
	keywords = {proceedings},
	publisher = {ACM Press},
	title = {{Proceedings of the Fourth International Conference on Functional
          Programming Languages and Computer Architecture, FPCA 1989}},
	year = {1989}
}

@proceedings{proc:popl17,
	doi = {10.1145/3009837},
	editor = {Castagna, Giuseppe and Gordon, Andrew D.},
	isbn = {978-1-4503-4660-3},
	publisher = {{ACM Press}},
	title = {Proceedings of the 44th {ACM} {SIGPLAN} Symposium on Principles
          of Programming Languages, {POPL} 2017},
	doi = {10.1145/3009837},
	year = {2017}
}


@proceedings{proc:icfp15,
	booktitle = {{Proceedings of the 20th ACM SIGPLAN International Conference on Functional Programming, ICFP 2015}},
	editor = {Fisher, Kathleen and Reppy, John},
	location = {Vancouver, BC, Canada},
	publisher = {ACM Press},
	title = {{Proceedings of the 20th ACM SIGPLAN International Conference on Functional Programming, ICFP 2015}},
	year = {2015}
}


@proceedings{proc:popl08,
	booktitle = "{Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium
         on Principles of Programming Languages, POPL 2008}",
	date-added = "2012-11-12 10:32:04 -0500",
	date-modified = "2012-11-12 10:32:43 -0500",
	editor = "George Necula and Philip Wadler",
	keywords = "proceedings",
	publisher = "ACM Press",
	title = "{Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages}",
	year = "2008"
}

@proceedings{proc:popl03,
	booktitle = "{Proceedings of the 30th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages}",
	date-added = "2012-11-12 10:35:12 -0500",
	date-modified = "2012-11-12 10:36:44 -0500",
	editor = "Alex Aiken and Greg Morrisett",
	keywords = "proceedings",
	publisher = "ACM Press",
	title = "{Proceedings of the 30th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages}",
	year = "2003"
}

@article{rajani-et-al:popl21,
author = {Rajani, Vineet and Gaboardi, Marco and Garg, Deepak and Hoffmann, Jan},
title = {A Unifying Type-Theory for Higher-Order (Amortized) Cost Analysis},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {POPL},
url = {https://doi.org/10.1145/3434308},
doi = {10.1145/3434308},
abstract = {This paper presents λ-amor, a new type-theoretic framework for amortized cost analysis of higher-order functional programs and shows that existing type systems for cost analysis can be embedded in it. λ-amor introduces a new modal type for representing potentials – costs that have been accounted for, but not yet incurred, which are central to amortized analysis. Additionally, λ-amor relies on standard type-theoretic concepts like affineness, refinement types and an indexed cost monad. λ-amor is proved sound using a rather simple logical relation. We embed two existing type systems for cost analysis in λ-amor showing that, despite its simplicity, λ-amor can simulate cost analysis for different evaluation strategies (call-by-name and call-by-value), in different styles (effect-based and coeffect-based), and with or without amortization. One of the embeddings also implies that λ-amor is relatively complete for all terminating PCF programs.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {27},
numpages = {28},
keywords = {type theory, relative completeness, amortized cost analysis}
}

@article{moggi91,
  title={Notions of computation and monads},
  author={Moggi, Eugenio},
  journal={Information and computation},
  volume={93},
  number={1},
  pages={55--92},
  year={1991},
  publisher={Elsevier}
}

@article{kavvos:lmcs,
  title = {{Dual-Context Calculi for Modal Logic}},
  author = {Kavvos, G. A.},
  journalL = {{Logical Methods in Computer Science}},
  volume = {{Volume 16, Issue 3}},
  year = {2020},
  month = Aug,
}

@article{cervesato:tcs00,
  title={Efficient Resource Management for Linear Logic Proof Search},
  author={Cervesato, Iliano and Hodas, Joshua S and Pfenning, Frank},
  journal={Theoretical Computer Science},
  volume={232},
  number={1-2},
  pages={133--163},
  year={2000},
  publisher={Elsevier}
}

 @Unpublished{dunfield19:bidir-survey,
    author =    {Jana Dunfield and Neel Krishnaswami},
    title =     {Bidirectional Typing},
    year =      {2019},
    note =      {\url{arXiv:1908.05839 [cs.PL]}}
  }
  
  @article{xi:jfp07, title={Dependent ML, An Approach to Practical Programming with Dependent Types}, volume={17}, DOI={10.1017/S0956796806006216}, number={2}, journal={Journal of Functional Programming}, publisher={Cambridge University Press}, author={Xi, Hongwei}, year={2007}, pages={215–286}}
  
  
  @phdthesis{hoffmann:thesis,
    title    = {Types with Potential: Polynomial Resource Bounds via Automatic Amortized Analysis},
    school   = {LMU Munich},
    author   = {Hoffmann, Jan},
    year     = {2011}
}

@article{milner:jcss78,
	title={A theory of type polymorphism in programming},
	author={Milner, Robin},
	journal={JOURNAL OF COMPUTER AND SYSTEM SCIENCES},
	pages={348--375},
	year={1978}
}


@article{reed:icfp10,
author = {Reed, Jason and Pierce, Benjamin C.},
title = {Distance Makes the Types Grow Stronger: A Calculus for Differential Privacy},
year = {2010},
issue_date = {September 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/1932681.1863568},
doi = {10.1145/1932681.1863568},
month = sep,
pages = {157–168},
numpages = {12},
keywords = {type systems, differential privacy}
}

@article{downen-et-al:icfp20,
author = {Downen, Paul and Ariola, Zena M. and Peyton Jones, Simon and Eisenberg, Richard A.},
title = {Kinds Are Calling Conventions},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {ICFP},
url = {https://doi.org/10.1145/3408986},
doi = {10.1145/3408986},
abstract = {A language supporting polymorphism is a boon to programmers: they can express complex ideas once and reuse functions in a variety of situations. However, polymorphism is pain for compilers tasked with producing efficient code that manipulates concrete values.  This paper presents a new intermediate language that allows for efficient static compilation, while still supporting flexible polymorphism. Specifically, it permits polymorphism over not only the types of values, but also the representation of values, the arity of primitive machine functions, and the evaluation order of arguments---all three of which are useful in practice. The key insight is to encode information about a value's calling convention in the kind of its type, rather than in the type itself.},
journal = {Proc. ACM Program. Lang.},
month = aug,
articleno = {104},
numpages = {29},
keywords = {polymorphism, arity, representation, type systems, levity}
}

@article{wickline-et-al,
author = {Wickline, Philip and Lee, Peter and Pfenning, Frank and Davies, Rowan},
title = {Modal Types as Staging Specifications for Run-Time Code Generation},
year = {1998},
issue_date = {Sept. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3es},
issn = {0360-0300},
url = {https://doi.org/10.1145/289121.289129},
doi = {10.1145/289121.289129},
journal = {ACM Comput. Surv.},
month = sep,
pages = {8–es},
numpages = {7}
}

@article{rossberg-et-al:jfp14, title={F-ing modules}, volume={24}, DOI={10.1017/S0956796814000264}, number={5}, journal={Journal of Functional Programming}, publisher={Cambridge University Press}, author={ROSSBERG, ANDREAS and RUSSO, CLAUDIO and DREYER, DEREK}, year={2014}, pages={529–607}}

@article{honda-et-al:16,
author = {Honda, Kohei and Yoshida, Nobuko and Carbone, Marco},
title = {Multiparty Asynchronous Session Types},
year = {2016},
issue_date = {March 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {63},
number = {1},
issn = {0004-5411},
url = {https://doi.org/10.1145/2827695},
doi = {10.1145/2827695},
abstract = {Communication is a central elements in software development. As a potential typed foundation for structured communication-centered programming, session types have been studied over the past decade for a wide range of process calculi and programming languages, focusing on binary (two-party) sessions. This work extends the foregoing theories of binary session types to multiparty, asynchronous sessions, which often arise in practical communication-centered applications. Presented as a typed calculus for mobile processes, the theory introduces a new notion of types in which interactions involving multiple peers are directly abstracted as a global scenario. Global types retain the friendly type syntax of binary session types while specifying dependencies and capturing complex causal chains of multiparty asynchronous interactions. A global type plays the role of a shared agreement among communication peers and is used as a basis of efficient type-checking through its projection onto individual peers. The fundamental properties of the session type discipline, such as communication safety, progress, and session fidelity, are established for general n-party asynchronous interactions.},
journal = {J. ACM},
month = mar,
articleno = {9},
numpages = {67},
keywords = {global protocols, global types, progress, the pi-calculus, projection, Session types}
}

@inproceedings{hoffmann-et-al:cav12,
author = {Hoffmann, Jan and Aehlig, Klaus and Hofmann, Martin},
title = {Resource Aware ML},
year = {2012},
isbn = {9783642314230},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-31424-7_64},
doi = {10.1007/978-3-642-31424-7_64},
abstract = {The automatic determination of the quantitative resource consumption of programs is a classic research topic which has many applications in software development. Recently, we developed a novel multivariate amortized resource analysis that automatically computes polynomial resource bounds for first-order functional programs.In this tool paper, we describe Resource Aware ML (RAML), a functional programming language that implements our analysis. Other than in earlier articles, we focus on the practical aspects of the implementation. We describe the syntax of RAML, the code transformation prior to the analysis, the web interface, the output of the analysis, and the results of our experiments with the analysis of example programs.},
booktitle = {Proceedings of the 24th International Conference on Computer Aided Verification},
pages = {781–786},
numpages = {6},
keywords = {static analysis, resource consumption, amortized analysis, functional programming, quantitative analysis},
location = {Berkeley, CA},
series = {CAV'12}
}

@inproceedings{hoffmann-et-al:esop10,
author = {Hoffmann, Jan and Hofmann, Martin},
title = {Amortized Resource Analysis with Polynomial Potential: A Static Inference of Polynomial Bounds for Functional Programs},
year = {2010},
isbn = {3642119565},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-11957-6_16},
doi = {10.1007/978-3-642-11957-6_16},
abstract = {In 2003, Hofmann and Jost introduced a type system that uses a potential-based amortized analysis to infer bounds on the resource consumption of (first-order) functional programs. This analysis has been successfully applied to many standard algorithms but is limited to bounds that are linear in the size of the input.Here we extend this system to polynomial resource bounds. An automatic amortized analysis is used to infer these bounds for functional programs without further annotations if a maximal degree for the bounding polynomials is given. The analysis is generic in the resource and can obtain good bounds on heap-space, stack-space and time usage.},
booktitle = {Proceedings of the 19th European Conference on Programming Languages and Systems},
pages = {287–306},
numpages = {20},
keywords = {amortized analysis, resource consumption, static analysis, functional programming},
location = {Paphos, Cyprus},
series = {ESOP'10}
}

@article{pierce-and-turner:lti,
author = {Pierce, Benjamin C. and Turner, David N.},
title = {Local Type Inference},
year = {2000},
issue_date = {Jan. 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1},
issn = {0164-0925},
url = {https://doi.org/10.1145/345099.345100},
doi = {10.1145/345099.345100},
abstract = {We study two partial type inference methods for a language combining subtyping and impredicative polymorphism. Both methods are local in the sense that missing annotations are recovered using only information from adjacent nodes in the syntax tree, without long-distance constraints such as unification variables. One method infers type arguments in polymorphic applications using a local constraint solver. The other infers annotations on bound variables in function abstractions by propagating type constraints downward from enclosing application nodes. We motivate our design choices by a statistical analysis of the uses of type inference in a sizable body of existing ML code.},
journal = {ACM Trans. Program. Lang. Syst.},
month = jan,
pages = {1–44},
numpages = {44},
keywords = {subtyping, polymorphism, type inference}
}

@inproceedings{10.1145/2951913.2951939,
author = {Gaboardi, Marco and Katsumata, Shin-ya and Orchard, Dominic and Breuvart, Flavien and Uustalu, Tarmo},
title = {Combining Effects and Coeffects via Grading},
year = {2016},
isbn = {9781450342193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2951913.2951939},
doi = {10.1145/2951913.2951939},
abstract = { Effects and coeffects are two general, complementary aspects of program behaviour. They roughly correspond to computations which change the execution context (effects) versus computations which make demands on the context (coeffects). Effectful features include partiality, non-determinism, input-output, state, and exceptions. Coeffectful features include resource demands, variable access, notions of linearity, and data input requirements. The effectful or coeffectful behaviour of a program can be captured and described via type-based analyses, with fine grained information provided by monoidal effect annotations and semiring coeffects. Various recent work has proposed models for such typed calculi in terms of graded (strong) monads for effects and graded (monoidal) comonads for coeffects. Effects and coeffects have been studied separately so far, but in practice many computations are both effectful and coeffectful, e.g., possibly throwing exceptions but with resource requirements. To remedy this, we introduce a new general calculus with a combined effect-coeffect system. This can describe both the changes and requirements that a program has on its context, as well as interactions between these effectful and coeffectful features of computation. The effect-coeffect system has a denotational model in terms of effect-graded monads and coeffect-graded comonads where interaction is expressed via the novel concept of graded distributive laws. This graded semantics unifies the syntactic type theory with the denotational model. We show that our calculus can be instantiated to describe in a natural way various different kinds of interaction between a program and its evaluation context. },
booktitle = {Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming},
pages = {476–489},
numpages = {14},
keywords = {types, comonads, coeffects, grading, categorical semantics, monads, distributive laws, effects},
location = {Nara, Japan},
series = {ICFP 2016}
}

@article{gaboardi-et-al:icfp16,
author = {Gaboardi, Marco and Katsumata, Shin-ya and Orchard, Dominic and Breuvart, Flavien and Uustalu, Tarmo},
title = {Combining Effects and Coeffects via Grading},
year = {2016},
issue_date = {September 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/3022670.2951939},
doi = {10.1145/3022670.2951939},
abstract = { Effects and coeffects are two general, complementary aspects of program behaviour. They roughly correspond to computations which change the execution context (effects) versus computations which make demands on the context (coeffects). Effectful features include partiality, non-determinism, input-output, state, and exceptions. Coeffectful features include resource demands, variable access, notions of linearity, and data input requirements. The effectful or coeffectful behaviour of a program can be captured and described via type-based analyses, with fine grained information provided by monoidal effect annotations and semiring coeffects. Various recent work has proposed models for such typed calculi in terms of graded (strong) monads for effects and graded (monoidal) comonads for coeffects. Effects and coeffects have been studied separately so far, but in practice many computations are both effectful and coeffectful, e.g., possibly throwing exceptions but with resource requirements. To remedy this, we introduce a new general calculus with a combined effect-coeffect system. This can describe both the changes and requirements that a program has on its context, as well as interactions between these effectful and coeffectful features of computation. The effect-coeffect system has a denotational model in terms of effect-graded monads and coeffect-graded comonads where interaction is expressed via the novel concept of graded distributive laws. This graded semantics unifies the syntactic type theory with the denotational model. We show that our calculus can be instantiated to describe in a natural way various different kinds of interaction between a program and its evaluation context. },
journal = {SIGPLAN Not.},
month = sep,
pages = {476–489},
numpages = {14},
keywords = {coeffects, grading, types, distributive laws, effects, monads, categorical semantics, comonads}
}

@inproceedings{dunfield:popl04,
  author = {Jana Dunfield and Frank Pfenning},
  title = {Tridirectional Typechecking},
  booktitle = {Conference Record of the 31st Annual Symposium
                  on Principles of Programming Languages (POPL'04)},
  pages = {281--292},
  year = 2004,
  editor = {X.Leroy},
  address = {Venice, Italy},
  month = jan,
  publisher = {ACM Press},
  note = {Extended version available as Technical Report CMU-CS-04-117,
                  March 2004},
  urlpdf = {http://www.cs.cmu.edu/~fp/papers/popl04.pdf}
}

@article{zenger:tcs97,
author = {Zenger, Christoph},
title = {Indexed Types},
year = {1997},
issue_date = {Nov. 15, 1997},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {187},
number = {1–2},
issn = {0304-3975},
url = {https://doi.org/10.1016/S0304-3975(97)00062-5},
doi = {10.1016/S0304-3975(97)00062-5},
journal = {Theor. Comput. Sci.},
month = nov,
pages = {147–165},
numpages = {19},
keywords = {constraints, type system, type inference, functional languages, dependent types}
}

@inproceedings{boogie11why3,
  topics = {team},
  hal = {http://hal.inria.fr/hal-00790310},
  author = {Fran\c{c}ois Bobot and Jean-Christophe Filli\^atre and
Claude March\'e and Andrei Paskevich},
  title = {Why3: Shepherd Your Herd of Provers},
  booktitle = {Boogie 2011: First International Workshop on Intermediate Verification Languages},
  year = 2011,
  address = {Wroc\l{}aw, Poland},
  month = {August},
  pages = {53--64},
  note = {\url{https://hal.inria.fr/hal-00790310}},
  x-international-audience = {yes},
  x-proceedings = {yes},
  x-cle-support = {BOOGIE},
  x-type = {actes_aux},
  x-support = {article},
  x-equipes = {demons PROVAL},
  keywords = {Why3},
  abstract = {Why3 is the next generation of the
  Why software verification platform.
  Why3 clearly separates the purely logical
  specification part from generation of verification conditions for programs.
  This article focuses on the former part.
  Why3 comes with a new enhanced language of
  logical specification. It features a rich library of
  proof task transformations that can be chained to produce a suitable
  input for a large set of theorem provers, including SMT solvers,
  TPTP provers, as well as interactive proof assistants.}
}

@inproceedings{reynolds:acm72,
author = {Reynolds, John C.},
title = {Definitional Interpreters for Higher-Order Programming Languages},
year = {1972},
isbn = {9781450374927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800194.805852},
doi = {10.1145/800194.805852},
abstract = {Higher-order programming languages (i.e., languages in which procedures or labels can occur as values) are usually defined by interpreters which are themselves written in a programming language based on the lambda calculus (i.e., an applicative language such as pure LISP). Examples include McCarthy's definition of LISP, Landin's SECD machine, the Vienna definition of PL/I, Reynolds' definitions of GEDANKEN, and recent unpublished work by L. Morris and C. Wadsworth. Such definitions can be classified according to whether the interpreter contains higher-order functions, and whether the order of application (i.e., call-by-value versus call-by-name) in the defined language depends upon the order of application in the defining language. As an example, we consider the definition of a simple applicative programming language by means of an interpreter written in a similar language. Definitions in each of the above classifications are derived from one another by informal but constructive methods. The treatment of imperative features such as jumps and assignment is also discussed.},
booktitle = {Proceedings of the ACM Annual Conference - Volume 2},
pages = {717–740},
numpages = {24},
keywords = {Programming language, Order of application, Closure, Language definition, Interpreter, Applicative language, GEDANKEN, J-operator, PAL, Higher-order function, Reference, Continuation, Lambda calculus, LISP, SECD machine},
location = {Boston, Massachusetts, USA},
series = {ACM '72}
}

@inproceedings{omar-et-al:popl17,
  author    = {Cyrus Omar and Ian Voysey and Michael Hilton and Jonathan Aldrich and Matthew A. Hammer},
  title     = {{Hazelnut: A Bidirectionally Typed Structure Editor Calculus}},
  booktitle = {44th {ACM} {SIGPLAN} Symposium on
               Principles of Programming Languages ({POPL} 2017)},
  year      = {2017}
}

@article{orchard-et-al:popl19,
author = {Orchard, Dominic and Liepelt, Vilem-Benjamin and Eades III, Harley},
title = {Quantitative Program Reasoning with Graded Modal Types},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {ICFP},
url = {https://doi.org/10.1145/3341714},
doi = {10.1145/3341714},
abstract = {In programming, some data acts as a resource (e.g., file handles, channels) subject to usage constraints. This poses a challenge to software correctness as most languages are agnostic to constraints on data. The approach of linear types provides a partial remedy, delineating data into resources to be used but never copied or discarded, and unconstrained values. Bounded Linear Logic provides a more fine-grained approach, quantifying non-linear use via an indexed-family of modalities. Recent work on coeffect types generalises this idea to graded comonads, providing type systems which can capture various program properties. Here, we propose the umbrella notion of graded modal types, encompassing coeffect types and dual notions of type-based effect reasoning via graded monads. In combination with linear and indexed types, we show that graded modal types provide an expressive type theory for quantitative program reasoning, advancing the reach of type systems to capture and verify a broader set of program properties. We demonstrate this approach via a type system embodied in a fully-fledged functional language called Granule, exploring various examples.},
journal = {Proc. ACM Program. Lang.},
month = jul,
articleno = {110},
numpages = {30},
keywords = {linear types, graded modal types, coeffects, implementation}
}

@article{wells:pal91,
title = {Typability and type checking in System F are equivalent and undecidable},
journal = {Annals of Pure and Applied Logic},
volume = {98},
number = {1},
pages = {111-156},
year = {1999},
issn = {0168-0072},
doi = {https://doi.org/10.1016/S0168-0072(98)00047-5},
url = {https://www.sciencedirect.com/science/article/pii/S0168007298000475},
author = {J.B. Wells},
keywords = {System F, Semi-unification, Type inference, Typability, Type checking, Lambda calculus},
abstract = {Girard and Reynolds independently invented System F (a.k.a. the second-order polymorphically typed lambda calculus) to handle problems in logic and computer programming language design, respectively. Viewing F in the Curry style, which associates types with untyped lambda terms, raises the questions of typability and type checking. Typability asks for a term whether there exists some type it can be given. Type checking asks, for a particular term and type, whether the term can be given that type. The decidability of these problems has been settled for restrictions and extensions of F and related systems and complexity lower-bounds have been determined for typability in F, but this report is the first to resolve whether these problems are decidable for System F. This report proves that type checking in F is undecidable, by a reduction from semi-unification, and that typability in F is undecidable, by a reduction from type checking. Because there is an easy reduction from typability to type checking, the two problems are equivalent. The reduction from type checking to typability uses a novel method of constructing lambda terms that simulate arbitrarily chosen type environments. All of the results also hold for the Î»I-calculus.}
}

@article{ringer-et-al:qed,
   title={QED at Large: A Survey of Engineering of Formally Verified Software},
   volume={5},
   ISSN={2325-1131},
   url={http://dx.doi.org/10.1561/2500000045},
   DOI={10.1561/2500000045},
   number={2-3},
   journal={Foundations and Trends® in Programming Languages},
   publisher={Now Publishers},
   author={Ringer, Talia and Palmskog, Karl and Sergey, Ilya and Gligoric, Milos and Tatlock, Zachary},
   year={2019},
   pages={102–281}
}

@unpublished{korkut-et-al:regex,
  title = {Intrinsic Verification of a Regular Expression Matcher},
  author = {Joomy Korkut and Maksim Trifunovski and Daniel R. Licata}
}

@article{spsm, title = "SECURITY POLICIES AND SECURITY MODELS.", author = "Goguen, {J. A.} and Jose Meseguer", year = "1982", language = "English (US)", pages = "11--20", journal = "Proceedings of the IEEE Computer Society Symposium on Research in Security and Privacy", issn = "1063-7109", publisher = "Institute of Electrical and Electronics Engineers Inc.", }

@online{coq,
  author = {{The Coq Development Team}},
  title = {{The Coq Proof Assistant}},
  year={1989 - 2021},
  url = {http://coq.inria.fr/},
  urldate = {2021-04-04}
}

@online{rust,
  author = {{The Rust Core Team}},
  title = {{Rust}},
  year={2010 - 2021},
  url = {http://rust-lang.org/},
  urldate = {2021-04-08}
}

@online{d-lang,
  author = {{The D Language Foundation}},
  title = {{D}},
  year={2007 - 2021},
  url = {http://dlang.org/},
  urldate = {2021-04-08}
}

@online{typescript,
  author = {{Microsoft}},
  title = {{TypeScript}},
  year={2012 - 2021},
  url = {http://typescriptlang.org/},
  urldate = {2021-04-08}
}

@online{haskell,
  author = {{The Coq Development Team}},
  title = {{The Coq Proof Assistant}},
  year={1989 - 2021},
  url = {http://coq.inria.fr/},
  urldate = {2021-04-04}
}


@inproceedings{norell:afp08,
author = {Norell, Ulf},
title = {Dependently Typed Programming in Agda},
year = {2008},
isbn = {3642046517},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Proceedings of the 6th International Conference on Advanced Functional Programming},
pages = {230–266},
numpages = {37},
location = {Heijen, The Netherlands},
series = {AFP'08}
}

@InProceedings{swamy-et-al:pldi13,
author = {Swamy, Nikhil and Chen, Juan and Livshits, Ben},
title = {Verifying Higher-order Programs with the Dijkstra Monad},
booktitle = {ACM Programming Language Design and Implementation (PLDI) 2013},
year = {2013},
month = {June},
publisher = {ACM},
url = {https://www.microsoft.com/en-us/research/publication/verifying-higher-order-programs-with-the-dijkstra-monad/},
edition = {ACM Programming Language Design and Implementation (PLDI) 2013},
}

@misc{niu-harper:catt,
      title={Cost-Aware Type Theory}, 
      author={Yue Niu and Robert Harper},
      year={2020},
      eprint={2011.03660},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}

@article{koth-et-al:icfp20,
author = {Knoth, Tristan and Wang, Di and Reynolds, Adam and Hoffmann, Jan and Polikarpova, Nadia},
title = {Liquid Resource Types},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {ICFP},
url = {https://doi.org/10.1145/3408988},
doi = {10.1145/3408988},
abstract = {This article presents liquid resource types, a technique for automatically verifying the resource consumption of functional programs. Existing resource analysis techniques trade automation for flexibility – automated techniques are restricted to relatively constrained families of resource bounds, while more expressive proof techniques admitting value-dependent bounds rely on handwritten proofs. Liquid resource types combine the best of these approaches, using logical refinements to automatically prove precise bounds on a program’s resource consumption. The type system augments refinement types with potential annotations to conduct an amortized resource analysis. Importantly, users can annotate data structure declarations to indicate how potential is allocated within the type, allowing the system to express bounds with polynomials and exponentials, as well as more precise expressions depending on program values. We prove the soundness of the type system, provide a library of flexible and reusable data structures for conducting resource analysis, and use our prototype implementation to automatically verify resource bounds that previously required a manual proof.},
journal = {Proc. ACM Program. Lang.},
month = aug,
articleno = {106},
numpages = {29},
keywords = {Automated amortized resource analysis, Refinement types}
}

@article{handley-et-al:popl20,
author = {Handley, Martin A. T. and Vazou, Niki and Hutton, Graham},
title = {Liquidate Your Assets: Reasoning about Resource Usage in Liquid Haskell},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {POPL},
url = {https://doi.org/10.1145/3371092},
doi = {10.1145/3371092},
abstract = {Liquid Haskell is an extension to the type system of Haskell that supports formal reasoning about program correctness by encoding logical properties as refinement types. In this article, we show how Liquid Haskell can also be used to reason about program efficiency in the same setting. We use the system's existing verification machinery to ensure that the results of our cost analysis are valid, together with custom invariants for particular program contexts to ensure that the results of our analysis are precise. To illustrate our approach, we analyse the efficiency of a wide range of popular data structures and algorithms, and in doing so, explore various notions of resource usage. Our experience is that reasoning about efficiency in Liquid Haskell is often just as simple as reasoning about correctness, and that the two can naturally be combined.},
journal = {Proc. ACM Program. Lang.},
month = dec,
articleno = {24},
numpages = {27},
keywords = {refinement types, static verification, resource analysis}
}

@InProceedings{mccarthy-et-al:flops16,
author="McCarthy, Jay
and Fetscher, Burke
and New, Max
and Feltey, Daniel
and Findler, Robert Bruce",
editor="Kiselyov, Oleg
and King, Andy",
title="A Coq Library for Internal Verification of Running-Times",
booktitle="Functional and Logic Programming",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="144--162",
abstract="This paper presents a Coq library that lifts an abstract yet precise notion of running-time into the type of a function. Our library is based on a monad that counts abstract steps, controlled by one of the monadic operations. The monad's computational content, however, is simply that of the identity monad so programs written in our monad (that recur on the natural structure of their arguments) extract into idiomatic OCaml code. We evaluated the expressiveness of the library by proving that red-black tree insertion and search, merge sort, insertion sort, Fibonacci, iterated list insertion, BigNum addition, and Okasaki's Braun Tree algorithms all have their expected running times.",
isbn="978-3-319-29604-3"
}

@inproceedings{cicek-et-al:pldi19,
author = {\c{C}i\c{c}ek, Ezgi and Qu, Weihao and Barthe, Gilles and Gaboardi, Marco and Garg, Deepak},
title = {Bidirectional Type Checking for Relational Properties},
year = {2019},
isbn = {9781450367127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314221.3314603},
doi = {10.1145/3314221.3314603},
abstract = {Relational type systems have been designed for several applications including information flow, differential privacy, and cost analysis. In order to achieve the best results, these systems often use relational refinements and relational effects to maximally exploit the similarity in the structure of the two programs being compared. Relational type systems are appealing for relational properties because they deliver simpler and more precise verification than what could be derived from typing the two programs separately. However, relational type systems do not yet achieve the practical appeal of their non-relational counterpart, in part because of the lack of a general foundation for implementing them.  In this paper, we take a step in this direction by developing bidirectional relational type checking for systems with relational refinements and effects. Our approach achieves the benefits of bidirectional type checking, in a relational setting. In particular, it significantly reduces the need for typing annotations through the combination of type checking and type inference. In order to highlight the foundational nature of our approach, we develop bidirectional versions of several relational type systems which incrementally combine many different components needed for expressive relational analysis.},
booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {533–547},
numpages = {15},
keywords = {relational type systems, type-and-effect systems, Bidirectional type-checking, refinement types},
location = {Phoenix, AZ, USA},
series = {PLDI 2019}
}

@inproceedings{de2008z3,
  title={Z3: An efficient SMT solver},
  author={De Moura, Leonardo and Bj{\o}rner, Nikolaj},
  booktitle={International conference on Tools and Algorithms for the Construction and Analysis of Systems},
  pages={337--340},
  year={2008},
  organization={Springer}
}

@inproceedings{lucassen1988polymorphic,
  title={Polymorphic effect systems},
  author={Lucassen, John M and Gifford, David K},
  booktitle={Proceedings of the 15th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
  pages={47--57},
  year={1988}
}

@article{plotkin2002computational,
  title={Computational effects and operations: An overview},
  author={Plotkin, Gordon and Power, John},
  year={2002}
}

@article{brady:jfp13,
  title={Idris, a general-purpose dependently typed programming language: Design and implementation},
  author={BRADY, EDWIN},
  journal={Journal of Functional Programming},
  volume={23},
  number={5},
  pages={552--593},
  year={2013},
  publisher={Cambridge University Press}
}

@misc{danner2021denotational,
      title={Denotational semantics as a foundation for cost recurrence extraction for functional languages}, 
      author={Norman Danner and Daniel R. Licata},
      year={2021},
      eprint={2002.07262},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}

@inproceedings{10.1145/2628136.2628161,
author = {Vazou, Niki and Seidel, Eric L. and Jhala, Ranjit and Vytiniotis, Dimitrios and Peyton-Jones, Simon},
title = {Refinement Types for Haskell},
year = {2014},
isbn = {9781450328739},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2628136.2628161},
doi = {10.1145/2628136.2628161},
abstract = {SMT-based checking of refinement types for call-by-value languages is a well-studied subject. Unfortunately, the classical translation of refinement types to verification conditions is unsound under lazy evaluation. When checking an expression, such systems implicitly assume that all the free variables in the expression are bound to values. This property is trivially guaranteed by eager, but does not hold under lazy, evaluation. Thus, to be sound and precise, a refinement type system for Haskell and the corresponding verification conditions must take into account which subset of binders actually reduces to values. We present a stratified type system that labels binders as potentially diverging or not, and that (circularly) uses refinement types to verify the labeling. We have implemented our system in LIQUIDHASKELL and present an experimental evaluation of our approach on more than 10,000 lines of widely used Haskell libraries. We show that LIQUIDHASKELL is able to prove 96% of all recursive functions terminating, while requiring a modest 1.7 lines of termination-annotations per 100 lines of code.},
booktitle = {Proceedings of the 19th ACM SIGPLAN International Conference on Functional Programming},
pages = {269–282},
numpages = {14},
location = {Gothenburg, Sweden},
series = {ICFP '14}
}

@article{vazou-et-al:icfp14,
author = {Vazou, Niki and Seidel, Eric L. and Jhala, Ranjit and Vytiniotis, Dimitrios and Peyton-Jones, Simon},
title = {Refinement Types for Haskell},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/2692915.2628161},
doi = {10.1145/2692915.2628161},
abstract = {SMT-based checking of refinement types for call-by-value languages is a well-studied subject. Unfortunately, the classical translation of refinement types to verification conditions is unsound under lazy evaluation. When checking an expression, such systems implicitly assume that all the free variables in the expression are bound to values. This property is trivially guaranteed by eager, but does not hold under lazy, evaluation. Thus, to be sound and precise, a refinement type system for Haskell and the corresponding verification conditions must take into account which subset of binders actually reduces to values. We present a stratified type system that labels binders as potentially diverging or not, and that (circularly) uses refinement types to verify the labeling. We have implemented our system in LIQUIDHASKELL and present an experimental evaluation of our approach on more than 10,000 lines of widely used Haskell libraries. We show that LIQUIDHASKELL is able to prove 96% of all recursive functions terminating, while requiring a modest 1.7 lines of termination-annotations per 100 lines of code.},
journal = {SIGPLAN Not.},
month = aug,
pages = {269–282},
numpages = {14}
}


@inproceedings{10.1145/2737924.2737955,
author = {Carbonneaux, Quentin and Hoffmann, Jan and Shao, Zhong},
title = {Compositional Certified Resource Bounds},
year = {2015},
isbn = {9781450334686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2737924.2737955},
doi = {10.1145/2737924.2737955},
abstract = { This paper presents a new approach for automatically deriving worst-case resource bounds for C programs. The described technique combines ideas from amortized analysis and abstract interpretation in a unified framework to address four challenges for state-of-the-art techniques: compositionality, user interaction, generation of proof certificates, and scalability. Compositionality is achieved by incorporating the potential method of amortized analysis. It enables the derivation of global whole-program bounds with local derivation rules by naturally tracking size changes of variables in sequenced loops and function calls. The resource consumption of functions is described abstractly and a function call can be analyzed without access to the function body. User interaction is supported with a new mechanism that clearly separates qualitative and quantitative verification. A user can guide the analysis to derive complex non-linear bounds by using auxiliary variables and assertions. The assertions are separately proved using established qualitative techniques such as abstract interpretation or Hoare logic. Proof certificates are automatically generated from the local derivation rules. A soundness proof of the derivation system with respect to a formal cost semantics guarantees the validity of the certificates. Scalability is attained by an efficient reduction of bound inference to a linear optimization problem that can be solved by off-the-shelf LP solvers. The analysis framework is implemented in the publicly-available tool C4B. An experimental evaluation demonstrates the advantages of the new technique with a comparison of C4B with existing tools on challenging micro benchmarks and the analysis of more than 2900 lines of C code from the cBench benchmark suite. },
booktitle = {Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {467–478},
numpages = {12},
keywords = {Amortized Analysis, Resource Bound Analysis, Program Logic, Static Analysis, Quantitative Verification, LP Solving},
location = {Portland, OR, USA},
series = {PLDI '15}
}

@article{carbonneaux-et-al:pldi15,
author = {Carbonneaux, Quentin and Hoffmann, Jan and Shao, Zhong},
title = {Compositional Certified Resource Bounds},
year = {2015},
issue_date = {June 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/2813885.2737955},
doi = {10.1145/2813885.2737955},
abstract = { This paper presents a new approach for automatically deriving worst-case resource bounds for C programs. The described technique combines ideas from amortized analysis and abstract interpretation in a unified framework to address four challenges for state-of-the-art techniques: compositionality, user interaction, generation of proof certificates, and scalability. Compositionality is achieved by incorporating the potential method of amortized analysis. It enables the derivation of global whole-program bounds with local derivation rules by naturally tracking size changes of variables in sequenced loops and function calls. The resource consumption of functions is described abstractly and a function call can be analyzed without access to the function body. User interaction is supported with a new mechanism that clearly separates qualitative and quantitative verification. A user can guide the analysis to derive complex non-linear bounds by using auxiliary variables and assertions. The assertions are separately proved using established qualitative techniques such as abstract interpretation or Hoare logic. Proof certificates are automatically generated from the local derivation rules. A soundness proof of the derivation system with respect to a formal cost semantics guarantees the validity of the certificates. Scalability is attained by an efficient reduction of bound inference to a linear optimization problem that can be solved by off-the-shelf LP solvers. The analysis framework is implemented in the publicly-available tool C4B. An experimental evaluation demonstrates the advantages of the new technique with a comparison of C4B with existing tools on challenging micro benchmarks and the analysis of more than 2900 lines of C code from the cBench benchmark suite. },
journal = {SIGPLAN Not.},
month = jun,
pages = {467–478},
numpages = {12},
keywords = {Program Logic, Resource Bound Analysis, LP Solving, Static Analysis, Quantitative Verification, Amortized Analysis}
}


@article{chargueraud-et-al:jar19,
	Abstract = {Union-Find is a famous example of a simple data structure whose amortized asymptotic time complexity analysis is nontrivial. We present a Coq formalization of this analysis, following Alstrup et al.'s recent proof. Moreover, we implement Union-Find as an OCaml library and formally endow it with a modular specification that offers a full functional correctness guarantee as well as an amortized complexity bound. In order to reason in Coq about imperative OCaml code, we use the CFML tool, which implements Separation Logic for a subset of OCaml, and which we extend with time credits. Although it was known in principle that amortized analysis can be explained in terms of time credits and that time credits can be viewed as resources in Separation Logic, we believe our work is the first practical demonstration of this approach. Finally, in order to explain the meta-theoretical foundations of our approach, we define a Separation Logic with time credits for an untyped call-by-value {\$}{\$}{$\backslash$}lambda {\$}{\$}-calculus, and formally verify its soundness.},
	Author = {Chargu{\'e}raud, Arthur and Pottier, Fran{\c c}ois},
	Da = {2019/03/01},
	Date-Added = {2021-04-09 03:32:44 +0000},
	Date-Modified = {2021-04-09 03:32:44 +0000},
	Doi = {10.1007/s10817-017-9431-7},
	Id = {Chargu{\'e}raud2019},
	Isbn = {1573-0670},
	Journal = {Journal of Automated Reasoning},
	Number = {3},
	Pages = {331--365},
	Title = {Verifying the Correctness and Amortized Complexity of a Union-Find Implementation in Separation Logic with Time Credits},
	Ty = {JOUR},
	Url = {https://doi.org/10.1007/s10817-017-9431-7},
	Volume = {62},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10817-017-9431-7},
	Bdsk-Url-2 = {http://dx.doi.org/10.1007/s10817-017-9431-7}}


@misc{li2021reasoning,
      title={Reasoning about the garden of forking paths}, 
      author={Yao Li and Li-yao Xia and Stephanie Weirich},
      year={2021},
      eprint={2103.07543},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}

@article{ohearn:popl20,
author = {O'Hearn, Peter W.},
title = {Incorrectness Logic},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {POPL},
url = {https://doi.org/10.1145/3371078},
doi = {10.1145/3371078},
abstract = {Program correctness and incorrectness are two sides of the same coin. As a programmer, even if you would like to have correctness, you might find yourself spending most of your time reasoning about incorrectness. This includes informal reasoning that people do while looking at or thinking about their code, as well as that supported by automated testing and static analysis tools. This paper describes a simple logic for program incorrectness which is, in a sense, the other side of the coin to Hoare's logic of correctness.},
journal = {Proc. ACM Program. Lang.},
month = dec,
articleno = {10},
numpages = {32},
keywords = {none}
}

@inproceedings{atkey:lics18,
author = {Atkey, Robert},
title = {Syntax and Semantics of Quantitative Type Theory},
year = {2018},
isbn = {9781450355834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209108.3209189},
doi = {10.1145/3209108.3209189},
abstract = {We present Quantitative Type Theory, a Type Theory that records usage information for each variable in a judgement, based on a previous system by McBride. The usage information is used to give a realizability semantics using a variant of Linear Combinatory Algebras, refining the usual realizability semantics of Type Theory by accurately tracking resource behaviour. We define the semantics in terms of Quantitative Categories with Families, a novel extension of Categories with Families for modelling resource sensitive type theories.},
booktitle = {Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science},
pages = {56–65},
numpages = {10},
keywords = {Type Theory, Linear Logic},
location = {Oxford, United Kingdom},
series = {LICS '18}
}

@article{choudhury-et-al:popl21,
author = {Choudhury, Pritam and Eades III, Harley and Eisenberg, Richard A. and Weirich, Stephanie},
title = {A Graded Dependent Type System with a Usage-Aware Semantics},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {POPL},
url = {https://doi.org/10.1145/3434331},
doi = {10.1145/3434331},
abstract = {Graded Type Theory provides a mechanism to track and reason about resource usage in type systems. In this paper, we develop GraD, a novel version of such a graded dependent type system that includes functions, tensor products, additive sums, and a unit type. Since standard operational semantics is resource-agnostic, we develop a heap-based operational semantics and prove a soundness theorem that shows correct accounting of resource usage. Several useful properties, including the standard type soundness theorem, non-interference of irrelevant resources in computation and single pointer property for linear resources, can be derived from this theorem. We hope that our work will provide a base for integrating linearity, irrelevance and dependent types in practical programming languages like Haskell.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {50},
numpages = {32},
keywords = {heap semantics, Irrelevance, linearity, quantitative reasoning}
}

@phdthesis{mcbride:thesis,
    title    = {Dependently Typed Functional Programs and their Proofs},
    school   = {University of Edinburgh},
    author   = {McBride, Connor},
    year     = {2000}
}

@InProceedings{mevel-et-al:esop19,
author="M{\'e}vel, Glen
and Jourdan, Jacques-Henri
and Pottier, Fran{\c{c}}ois",
editor="Caires, Lu{\'i}s",
title="Time Credits and Time Receipts in Iris",
booktitle="Programming Languages and Systems",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="3--29",
abstract="We present a machine-checked extension of the program logic Iris with time credits and time receipts, two dual means of reasoning about time. Whereas time credits are used to establish an upper bound on a program's execution time, time receipts can be used to establish a lower bound. More strikingly, time receipts can be used to prove that certain undesirable events---such as integer overflows---cannot occur until a very long time has elapsed. We present several machine-checked applications of time credits and time receipts, including an application where both concepts are exploited.",
isbn="978-3-030-17184-1"
}

